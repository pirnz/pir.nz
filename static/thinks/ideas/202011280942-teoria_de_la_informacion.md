```{=org}
#+CREATED: [2020-11-28 sáb 10:42]
```
```{=org}
#+ROAM_TAGS: 
```
```{=org}
#+FILETAGS: 
```
# Teoría de la información {#teoría-de-la-información-1}

Define que la comunicación tiene una fuente, mensaje, canal (que puede
presentar ruido), señal, receptor. La información contenida en un
mensaje se puede cuantificar midiendo su entropía. Esta entropía se
puede definir como la probabilidad de que ciertos mensajes sean emitidos
por la fuente. Si tomamos como ejemplo una fuente emitiendo letra por
letra un mensaje en castellano, ciertas letras tienen mucha más
probabilidad que otras.
